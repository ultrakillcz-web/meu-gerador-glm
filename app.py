import streamlit as st

def generate_glm_prompt(task_type, context, tech_stack, complexity):
    thinking_instruction = ""
    if complexity == "Alta (Deep Thinking)":
        thinking_instruction = "Utilize o modo 'Preserved Thinking' para decompor esta tarefa em sub-etapas l√≥gicas antes de escrever qualquer c√≥digo."
    
    prompt = f"""
### SISTEMA: MODO FULL-STACK EXPERT (GLM-4.7)
Voc√™ √© um Engenheiro de Software Full-stack Senior especializado em GLM-4.7 Agentic Workflows.
{thinking_instruction}

### OBJETIVO
{context}

### TECH STACK OBRIGAT√ìRIA
{tech_stack}

### DIRETRIZES DE EXECU√á√ÉO (VIBE CODING)
1. UI/UX: Utilize Tailwind CSS e priorize uma est√©tica moderna e minimalista.
2. ESTRUTURA: Gere um boilerplate completo, incluindo configura√ß√µes de backend e integra√ß√£o de banco de dados se necess√°rio.
3. QUALIDADE: O c√≥digo deve ser 'production-ready', com tratamento de erros e tipagem estrita.
4. AGENTIC: Se precisar de ferramentas externas, descreva o plano de a√ß√£o antes da execu√ß√£o.

### TAREFA ESPEC√çFICA
Tipo de Tarefa: {task_type}
Por favor, forne√ßa o plano de arquitetura seguido pela implementa√ß√£o completa dos arquivos.
"""
    return prompt

# Interface Streamlit
st.set_page_config(page_title="GLM-4.7 Prompt Generator", page_icon="üöÄ")
st.title("üöÄ GLM-4.7 Prompt Generator")
st.markdown("Gerador de prompts otimizados para a fun√ß√£o Full-stack do novo GLM-4.7.")

with st.form("prompt_form"):
    task_type = st.selectbox("Tipo de Projeto", ["Web App Full-stack", "Automa√ß√£o de API", "Refatora√ß√£o de C√≥digo", "Dashboards de Dados"])
    tech_stack = st.text_input("Stack Tecnol√≥gica (ex: Next.js, FastAPI, Supabase, Tailwind)", "Next.js, Tailwind, TypeScript")
    complexity = st.radio("N√≠vel de Racioc√≠nio", ["Padr√£o", "Alta (Deep Thinking)"])
    context = st.text_area("Descreva o que o app deve fazer:", "Crie um sistema de gerenciamento de tarefas com autentica√ß√£o e drag-and-drop.")
    
    submitted = st.form_submit_button("Gerar Prompt")

if submitted:
    final_prompt = generate_glm_prompt(task_type, context, tech_stack, complexity)
    st.subheader("Seu Prompt para o GLM-4.7:")
    st.code(final_prompt, language="markdown")
    st.info("üí° Dica: No chat.z.ai, certifique-se de que o modelo GLM-4.7 est√° selecionado para melhores resultados com este prompt.")
